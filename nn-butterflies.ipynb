{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12581365,"sourceType":"datasetVersion","datasetId":7945927}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset, random_split\nfrom torchvision import transforms, models, datasets\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nfrom tqdm import tqdm\nimport re\n\n\ntrain_dir = \"/kaggle/input/butterflies/train_butterflies/\"\ntest_dir = \"/kaggle/input/butterflies/test_butterflies/\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:54.006930Z","iopub.execute_input":"2025-07-29T13:02:54.007250Z","iopub.status.idle":"2025-07-29T13:02:54.012768Z","shell.execute_reply.started":"2025-07-29T13:02:54.007214Z","shell.execute_reply":"2025-07-29T13:02:54.012018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# предварительное исследование\nclasses = sorted([d for d in os.listdir(train_dir)])\n# print(classes)\n\ntotal = 0\nbalance_ = dict()\nresolutions = set()\n\nfor class_ in classes:\n    class_path = os.path.join(train_dir, class_)\n    balance_[class_] = 0\n    class_images = [_ for _ in os.listdir(class_path)]\n\n    for image in class_images:\n        img_path = os.path.join(class_path, image)\n        total += 1\n        balance_[class_] += 1\n        with Image.open(img_path) as img:\n            width, height = img.size\n            resolutions.add((width, height))\n\nbalance = sorted(balance_.items(), key=lambda item: item[1])\nprint(\"Всего изображений\", total) # 4955\nprint(\"Разрешение:\", resolutions) # 224 * 224 ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:54.014178Z","iopub.execute_input":"2025-07-29T13:02:54.014394Z","iopub.status.idle":"2025-07-29T13:02:57.128580Z","shell.execute_reply.started":"2025-07-29T13:02:54.014376Z","shell.execute_reply":"2025-07-29T13:02:57.127810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nclasses = [item[0] for item in balance]\nvalues = [item[1] for item in balance]\n\nplt.figure(figsize=(14, 6))\nplt.plot(classes, values, marker='o')\nplt.xticks(rotation=90)\nplt.title('Количество изображений в классе')\nplt.xlabel('Класс')\nplt.ylabel('Количество')\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.129519Z","iopub.execute_input":"2025-07-29T13:02:57.129752Z","iopub.status.idle":"2025-07-29T13:02:57.504246Z","shell.execute_reply.started":"2025-07-29T13:02:57.129729Z","shell.execute_reply":"2025-07-29T13:02:57.503474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# функция для рисования кривых обучения\ndef plot_training_curves(train_loss, val_loss, train_acc, val_acc):\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\n    axes[0].plot(train_loss, label='Train Loss', linewidth=2)\n    axes[0].plot(val_loss, label='Val Loss', linewidth=2)\n    axes[0].set_title('Loss per Epoch', fontsize=14)\n    axes[0].set_xlabel('Epoch', fontsize=12)\n    axes[0].set_ylabel('Loss', fontsize=12)\n    axes[0].legend(loc='upper right', fontsize=10)\n\n    axes[1].plot(train_acc, label='Train Accuracy', linewidth=2)\n    axes[1].plot(val_acc, label='Val Accuracy', linewidth=2)\n    axes[1].set_title('Accuracy per Epoch', fontsize=14)\n    axes[1].set_xlabel('Epoch', fontsize=12)\n    axes[1].set_ylabel('Accuracy', fontsize=12)\n    axes[1].legend(loc='lower right', fontsize=10)\n\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.505640Z","iopub.execute_input":"2025-07-29T13:02:57.505882Z","iopub.status.idle":"2025-07-29T13:02:57.511453Z","shell.execute_reply.started":"2025-07-29T13:02:57.505862Z","shell.execute_reply":"2025-07-29T13:02:57.510872Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# подготовка данных\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # статистика ImageNet\n])\n\ntrain_dataset = datasets.ImageFolder(\n    root=train_dir,\n    transform=transform\n)\n\ntrain_ds, val_ds = random_split(train_dataset, [0.8, 0.2])\n\nbatch_size = 16\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.512124Z","iopub.execute_input":"2025-07-29T13:02:57.512419Z","iopub.status.idle":"2025-07-29T13:02:57.591459Z","shell.execute_reply.started":"2025-07-29T13:02:57.512392Z","shell.execute_reply":"2025-07-29T13:02:57.590982Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# датасет для тестовых данных (без меток)\nclass TestDataset(Dataset):\n    def __init__(self, root_dir, transform=None):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.image_files = sorted(\n            [os.path.join(root_dir, f) for f in os.listdir(root_dir)],\n            key=lambda x: int(re.search(r'(\\d+)', os.path.basename(x)).group(1)) # регулярка находит число в имени файла\n        )\n\n    def __getitem__(self, idx):\n        img_path = self.image_files[idx]\n        image = Image.open(img_path).convert('RGB')\n        if self.transform:\n            image = self.transform(image)\n        return image, os.path.basename(img_path)\n\n    def __len__(self):\n        return len(self.image_files)\n\ntest_dataset = TestDataset(root_dir=test_dir, transform=transform)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.592189Z","iopub.execute_input":"2025-07-29T13:02:57.592427Z","iopub.status.idle":"2025-07-29T13:02:57.599469Z","shell.execute_reply.started":"2025-07-29T13:02:57.592412Z","shell.execute_reply":"2025-07-29T13:02:57.598802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# первая модель - попытка натренировать с нуля\nclass BasicBlock1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(64, 128, 3, stride=2, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n        )\n        self.skip = nn.Sequential(\n            nn.Conv2d(64, 128, 1, stride=2, bias=False),\n            nn.BatchNorm2d(128)\n        )\n\n    def forward(self, x):\n        return (self.skip(x) + self.block(x)).relu()\n    \nclass BasicBlock2(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.block = nn.Sequential(\n            nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 128, 3, stride=1, padding=1, bias=False),\n            nn.BatchNorm2d(128),\n        )\n\n    def forward(self, x):\n        return (x + self.block(x)).relu()\n\nmodel = nn.Sequential( # попробуем обучить не слишком глубокую сеть\n    nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False),\n    nn.BatchNorm2d(64),\n    nn.MaxPool2d((3,3), stride=2, padding=1),\n    BasicBlock1(),\n    BasicBlock2(),\n    nn.AdaptiveAvgPool2d(1),\n    nn.Flatten(),\n    nn.Linear(128, 50)\n).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.600180Z","iopub.execute_input":"2025-07-29T13:02:57.600388Z","iopub.status.idle":"2025-07-29T13:02:57.629970Z","shell.execute_reply.started":"2025-07-29T13:02:57.600366Z","shell.execute_reply":"2025-07-29T13:02:57.629373Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# функция обучения модели\ndef train_model(model, num_epochs, optimizer, criterion, name):\n    max_acc = 0\n    \n    train_loss_list = []\n    val_loss_list = []\n    train_acc_list = []\n    val_acc_list = []\n    \n    for epoch in range(num_epochs):\n        # тренировка\n        model.train()\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n        \n        train_acc = 100. * correct / total\n        train_loss /= len(train_loader)\n        \n        # валидация\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for inputs, labels in val_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                \n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                total += labels.size(0)\n                correct += predicted.eq(labels).sum().item()\n        \n        val_acc = 100. * correct / total\n        val_loss /= len(val_loader)\n        \n        print(f\"Train Loss: {train_loss:.4f} | Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f} | Acc: {val_acc:.2f}%\")\n    \n        train_loss_list.append(train_loss)\n        val_loss_list.append(val_loss)\n        train_acc_list.append(train_acc)\n        val_acc_list.append(val_acc)\n    \n        if max_acc < val_acc:\n            max_acc = val_acc\n            torch.save(model.state_dict(), name)\n\n    plot_training_curves(train_loss_list, val_loss_list, train_acc_list, val_acc_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.630689Z","iopub.execute_input":"2025-07-29T13:02:57.630925Z","iopub.status.idle":"2025-07-29T13:02:57.641230Z","shell.execute_reply.started":"2025-07-29T13:02:57.630900Z","shell.execute_reply":"2025-07-29T13:02:57.640712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# обучим первую модель\nopt = optim.Adam(params=model.parameters(), lr=0.001, weight_decay=0.001)\nloss_func = nn.CrossEntropyLoss()\ntrain_model(model, 50, opt, loss_func, \"first_model.pth\") # поставил эпох побольше, чтобы потом прервать обучение при необходимости","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:02:57.643683Z","iopub.execute_input":"2025-07-29T13:02:57.644298Z","iopub.status.idle":"2025-07-29T13:13:35.074984Z","shell.execute_reply.started":"2025-07-29T13:02:57.644278Z","shell.execute_reply":"2025-07-29T13:13:35.074198Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# предсказание на тестовых данных\ndef form_prediction(name_of_data, model_to_predict, name_of_prediction):\n    model_to_predict.eval()\n    model_to_predict.load_state_dict(torch.load(name_of_data))\n    all_preds = []\n    filenames = []\n    \n    with torch.no_grad():\n        for inputs, names in test_loader:\n            inputs = inputs.to(device)\n            outputs = model_to_predict(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            filenames.extend(names)\n    \n    class_names = train_dataset.classes\n    class_preds = [class_names[p] for p in all_preds]\n    \n    results = []\n    for i, (fn, pred) in enumerate(zip(filenames, class_preds)):\n        class_num = int(pred.split('_')[1])\n        results.append({'index': i, 'label': class_num})\n    \n    df = pd.DataFrame(results)\n    df.to_csv(name_of_prediction, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:13:35.075753Z","iopub.execute_input":"2025-07-29T13:13:35.075973Z","iopub.status.idle":"2025-07-29T13:13:35.081877Z","shell.execute_reply.started":"2025-07-29T13:13:35.075956Z","shell.execute_reply":"2025-07-29T13:13:35.081201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# первая модель достигает порога 0.8 на валидационной выборке\n# скорее всего, у нее недостаточная глубина\n\nform_prediction(\"first_model.pth\", model, \"first_model_prediction.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:13:35.082629Z","iopub.execute_input":"2025-07-29T13:13:35.082887Z","iopub.status.idle":"2025-07-29T13:13:35.892241Z","shell.execute_reply.started":"2025-07-29T13:13:35.082865Z","shell.execute_reply":"2025-07-29T13:13:35.891508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# вторая модель - дообученная b3\nclass ButterflyClassifier(nn.Module):\n    def __init__(self): # внезапно, работает лучше без заморозки слоев, я проверял!\n        super().__init__()\n        self.base_model = models.efficientnet_b3(pretrained=True)\n        self.base_model.classifier = nn.Sequential(\n            nn.Dropout(p=0.4, inplace=True),\n            nn.Linear(self.base_model.classifier[1].in_features, 50)\n        )\n    \n    def forward(self, x):\n        return self.base_model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:13:35.893003Z","iopub.execute_input":"2025-07-29T13:13:35.893208Z","iopub.status.idle":"2025-07-29T13:13:35.898222Z","shell.execute_reply.started":"2025-07-29T13:13:35.893191Z","shell.execute_reply":"2025-07-29T13:13:35.897442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ButterflyClassifier().to(device)\n\nloss_func = nn.CrossEntropyLoss()\nopt = optim.Adam(model.parameters(), lr=0.001)\n\ntrain_model(model, 15, opt, loss_func, \"second_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:20:45.229885Z","iopub.execute_input":"2025-07-29T13:20:45.230702Z","iopub.status.idle":"2025-07-29T13:31:18.703539Z","shell.execute_reply.started":"2025-07-29T13:20:45.230677Z","shell.execute_reply":"2025-07-29T13:31:18.702867Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"form_prediction(\"second_model.pth\", model, \"second_model_prediction.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# попробуем изменить последнюю модель\nclass ButterflyClassifierUpdated(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.base_model = models.efficientnet_b3(pretrained=True)\n        self.base_model.classifier = nn.Sequential( # пробовал менять последние слои, эта архитектура показала себя лучше всего\n            nn.Dropout(p=0.4, inplace=True),\n            nn.Linear(self.base_model.classifier[1].in_features, 50)\n        )\n    \n    def forward(self, x):\n        return self.base_model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:57:20.720521Z","iopub.execute_input":"2025-07-29T13:57:20.721224Z","iopub.status.idle":"2025-07-29T13:57:20.725739Z","shell.execute_reply.started":"2025-07-29T13:57:20.721200Z","shell.execute_reply":"2025-07-29T13:57:20.725000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# добавим аугментации\naug_transform = transforms.Compose([\n    transforms.RandomAffine(degrees=(-20, 20), translate=(0.1, 0.1)), # /*\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.)),\n    transforms.RandomApply([transforms.GaussianBlur(3)], p=0.1),\n    transforms.RandomAdjustSharpness(1.5, p=0.3), # */\n    \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# придется заново создать датасеты\ntrain_dataset = datasets.ImageFolder(\n    root=train_dir,\n    transform=None\n)\n\ntrain_tmp, val_tmp = random_split(train_dataset, [0.8, 0.2])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:57:20.726879Z","iopub.execute_input":"2025-07-29T13:57:20.727118Z","iopub.status.idle":"2025-07-29T13:57:21.250380Z","shell.execute_reply.started":"2025-07-29T13:57:20.727097Z","shell.execute_reply":"2025-07-29T13:57:21.249643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TransformSubset(torch.utils.data.Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n\n    def __len__(self):\n        return len(self.subset)\n\ntrain_ds = TransformSubset(train_tmp, aug_transform)\nval_ds = TransformSubset(val_tmp, transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:57:21.251538Z","iopub.execute_input":"2025-07-29T13:57:21.251782Z","iopub.status.idle":"2025-07-29T13:57:21.257620Z","shell.execute_reply.started":"2025-07-29T13:57:21.251760Z","shell.execute_reply":"2025-07-29T13:57:21.257006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ButterflyClassifierUpdated().to(device)\nopt = optim.Adam(model.parameters(), lr=0.0001, amsgrad=True)\nloss_func = nn.CrossEntropyLoss()\ntrain_model(model, 25, opt, loss_func, \"third_model.pth\") # больше эпох, так как модель сложнее","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T13:57:21.258413Z","iopub.execute_input":"2025-07-29T13:57:21.258638Z","iopub.status.idle":"2025-07-29T14:20:30.378120Z","shell.execute_reply.started":"2025-07-29T13:57:21.258623Z","shell.execute_reply":"2025-07-29T14:20:30.377410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"form_prediction(\"third_model.pth\", model, \"third_model_prediction.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T14:20:30.379295Z","iopub.execute_input":"2025-07-29T14:20:30.379562Z","iopub.status.idle":"2025-07-29T14:20:31.656833Z","shell.execute_reply.started":"2025-07-29T14:20:30.379545Z","shell.execute_reply":"2025-07-29T14:20:31.656300Z"}},"outputs":[],"execution_count":null}]}